{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of spectrogram 0: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 1: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 2: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 3: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 4: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 5: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 6: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 7: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 8: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 9: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 10: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 11: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 12: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 13: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 14: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 15: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 16: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 17: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 18: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 19: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 20: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 21: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 22: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 23: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 24: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 25: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 26: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 27: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 28: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 29: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 30: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 31: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 32: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 33: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 34: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 35: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 36: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 37: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 38: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 39: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 40: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 41: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 42: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 43: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 44: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 45: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 46: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 47: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 48: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 49: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 50: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 51: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 52: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 53: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 54: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 55: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 56: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 57: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 58: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 59: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 60: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 61: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 62: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 63: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 64: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 65: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 66: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 67: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 68: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 69: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 70: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 71: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 72: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 73: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 74: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 75: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 76: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 77: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 78: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 79: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 80: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 81: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 82: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 83: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 84: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 85: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 86: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 87: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 88: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 89: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 90: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 91: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 92: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 93: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 94: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 95: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 96: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 97: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 98: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 99: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 100: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 101: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 102: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 103: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 104: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 105: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 106: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 107: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 108: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 109: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 110: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 111: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 112: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 113: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 114: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 115: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 116: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 117: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 118: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 119: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 120: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 121: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 122: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 123: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 124: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 125: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 126: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 127: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 128: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 129: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 130: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 131: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 132: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 133: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 134: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 135: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 136: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 137: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 138: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 139: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 140: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 141: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 142: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 143: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 144: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 145: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 146: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 147: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 148: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 149: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 150: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 151: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 152: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 153: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 154: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 155: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 156: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 157: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 158: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 159: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 160: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 161: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 162: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 163: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 164: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 165: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 166: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 167: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 168: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 169: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 170: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 171: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 172: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 173: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 174: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 175: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 176: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 177: torch.Size([1, 129, 121])\n",
      "Shape of spectrogram 178: torch.Size([1, 129, 121])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import torch.nn.functional as F  # Import F for padding\n",
    "\n",
    "# Path to the directory containing the saved NumPy arrays\n",
    "NUMPY_DIR = \"keystroke_spectrograms/numpy_arrays\"\n",
    "\n",
    "# Function to load all spectrograms from the directory\n",
    "def load_spectrograms_from_directory(directory):\n",
    "    spectrograms = []\n",
    "    keys = []\n",
    "    widths = []\n",
    "    filenames = os.listdir(directory)\n",
    "\n",
    "    # Loop through each file in the directory\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.npy'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "\n",
    "            # Load the NumPy array from file\n",
    "            spectrogram = np.load(file_path)\n",
    "\n",
    "            widths.append(spectrogram.shape[1])\n",
    "\n",
    "            key = re.search(r\"keystroke_\\d+_([A-Za-z])\\.npy\", filename).group(1)\n",
    "\n",
    "            # Convert the spectrogram to a PyTorch tensor\n",
    "            # Adding a channel dimension (1, height, width) for CNN input\n",
    "            spectrogram_tensor = torch.tensor(spectrogram).unsqueeze(0).float()  # Shape: (1, n_freq_bins, n_time_bins)\n",
    "\n",
    "            # next, add the tensor to a list\n",
    "            spectrograms.append(spectrogram_tensor)\n",
    "            keys.append(key)\n",
    "\n",
    "    return spectrograms, keys, max(widths)\n",
    "\n",
    "# Load all spectrograms from the specified directory\n",
    "spectrogram_tensors, keys, max_width = load_spectrograms_from_directory(NUMPY_DIR)\n",
    "\n",
    "assert len(spectrogram_tensors) == len(keys), \"The number of spectrograms and keys do not match!\"\n",
    "\n",
    "\n",
    "## Need to pad the spectrograms to the same width\n",
    "\n",
    "# Padding function\n",
    "def pad_tensor(tensor, max_width):\n",
    "    # Calculate padding size (for the width dimension)\n",
    "    current_width = tensor.shape[2]  # Index 2 is for the time dimension (width)\n",
    "    if current_width < max_width:\n",
    "        padding = max_width - current_width\n",
    "        # Pad with zeros on the right (width dimension)\n",
    "        return F.pad(tensor, (0, padding))  # Pad (left, right)\n",
    "    return tensor\n",
    "\n",
    "# Apply padding to all spectrograms\n",
    "for i in range(len(spectrogram_tensors)):\n",
    "    spectrogram_tensors[i] = pad_tensor(spectrogram_tensors[i], max_width)\n",
    "\n",
    "# Verify padding\n",
    "for i, spectrogram in enumerate(spectrogram_tensors):\n",
    "    print(f\"Shape of spectrogram {i}: {spectrogram.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character labels: ['s', 'j', 'f', 'g', 'f', 'a', 'b', 'i', 'u', 'm', 'h', 'g', 's', 'f', 'd', 'j', 'c', 'c', 'e', 'g', 'd', 'j', 'j', 'i', 'u', 'w', 'f', 'g', 'i', 'f', 'p', 'b', 'h', 'j', 'i', 't', 'r', 'y', 's', 'l', 'q', 'g', 'h', 'o', 'g', 't', 'k', 'j', 'l', 'y', 'h', 't', 's', 'e', 'l', 'h', 'f', 'j', 'v', 'h', 'u', 'j', 'u', 'f', 'm', 'd', 'o', 'p', 'c', 'j', 'g', 't', 'z', 'f', 'd', 't', 'j', 'g', 'p', 'r', 'y', 'k', 'q', 'k', 'c', 'r', 'i', 'i', 'u', 'r', 'h', 'h', 'j', 'y', 'y', 'l', 'd', 'h', 'k', 'n', 'p', 't', 'y', 'h', 'u', 's', 't', 'u', 'a', 'v', 'x', 'f', 'k', 'g', 'e', 'o', 'q', 'g', 'p', 'h', 't', 'h', 'f', 'v', 'h', 'i', 'n', 'u', 'i', 't', 'x', 't', 'p', 'f', 'o', 's', 'g', 'd', 'm', 't', 'o', 'j', 'g', 'f', 'o', 'v', 'h', 'r', 't', 't', 't', 'u', 'l', 't', 's', 'l', 't', 'b', 'z', 'a', 'w', 't', 'k', 'd', 'o', 'z', 'o', 'u', 'x', 'f', 'f', 'j', 'g', 'g', 'd', 's', 'y', 'n', 'f']\n",
      "Converted Tensor: tensor([18,  9,  5,  6,  5,  0,  1,  8, 20, 12,  7,  6, 18,  5,  3,  9,  2,  2,\n",
      "         4,  6,  3,  9,  9,  8, 20, 22,  5,  6,  8,  5, 15,  1,  7,  9,  8, 19,\n",
      "        17, 24, 18, 11, 16,  6,  7, 14,  6, 19, 10,  9, 11, 24,  7, 19, 18,  4,\n",
      "        11,  7,  5,  9, 21,  7, 20,  9, 20,  5, 12,  3, 14, 15,  2,  9,  6, 19,\n",
      "        25,  5,  3, 19,  9,  6, 15, 17, 24, 10, 16, 10,  2, 17,  8,  8, 20, 17,\n",
      "         7,  7,  9, 24, 24, 11,  3,  7, 10, 13, 15, 19, 24,  7, 20, 18, 19, 20,\n",
      "         0, 21, 23,  5, 10,  6,  4, 14, 16,  6, 15,  7, 19,  7,  5, 21,  7,  8,\n",
      "        13, 20,  8, 19, 23, 19, 15,  5, 14, 18,  6,  3, 12, 19, 14,  9,  6,  5,\n",
      "        14, 21,  7, 17, 19, 19, 19, 20, 11, 19, 18, 11, 19,  1, 25,  0, 22, 19,\n",
      "        10,  3, 14, 25, 14, 20, 23,  5,  5,  9,  6,  6,  3, 18, 24, 13,  5])\n"
     ]
    }
   ],
   "source": [
    "class KeystrokeDataset(Dataset):\n",
    "    def __init__(self, spectrograms_tensors, labels):\n",
    "        self.spectrograms = spectrograms_tensors\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.spectrograms)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.spectrograms[idx], self.labels[idx]\n",
    "    \n",
    "tensors,labels, _ = load_spectrograms_from_directory(NUMPY_DIR)\n",
    "\n",
    "## convert the keystroke tuple into a tensor\n",
    "tensors = spectrogram_tensors # adjusting the tensors to the padded spectrograms\n",
    "alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "char2idx = {char: idx for idx, char in enumerate(alphabet)}\n",
    "label_indices = [char2idx[char] for char in labels]\n",
    "\n",
    "label_tensor = torch.tensor(label_indices, dtype=torch.long)\n",
    "\n",
    "train_dataset = KeystrokeDataset(spectrogram_tensors,label_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "print(\"Character labels:\", labels)\n",
    "print(\"Converted Tensor:\", label_tensor)\n",
    "\n",
    "#test_dataset = KeystrokeDataset(test_spectrograms_tensors, test_labels)\n",
    "#test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeystrokeCNN(nn.Module):\n",
    "    def __init__(self,input_height=129, input_width=101, num_classes=26):\n",
    "        super(KeystrokeCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # (1, H, W) -> (32, H, W)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1) # (32, H, W) -> (64, H, W)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1) # (64, H, W) -> (128, H, W)\n",
    "\n",
    "        # Pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # Reduces dimensions by half (H/2, W/2)\n",
    "\n",
    "        # Calculate the final feature map size dynamically\n",
    "        self._to_linear = self._get_conv_output_size(input_height, input_width)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(self._to_linear, 512)  \n",
    "        self.fc2 = nn.Linear(512, num_classes)  # 26 output classes (A-Z)\n",
    "        #list(string.ascii_lowercase) for generating the output classes\n",
    "\n",
    "    def _get_conv_output_size(self, height, width):\n",
    "        \"\"\"Pass a dummy tensor to determine final feature map size after convolutions\"\"\"\n",
    "        x = torch.zeros(1, 1, height, width)  # Batch size = 1, 1 channel, (H, W)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        return x.numel()  # Flattened size\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Forward pass through convolutional layers\n",
    "\n",
    "        print(\"size of x\",x.shape)  # Debugging the shape before flattening\n",
    "\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        # Flatten the output from convolutional layers to feed into fully connected layers\n",
    "        #x = x.view(-1, 128 * 7 * 7)  # Adjust based on input size (H, W)\n",
    "        x = x.view(x.size(0), -1)  # Flatten dynamically\n",
    "\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = KeystrokeCNN()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of x torch.Size([64, 1, 129, 121])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x30720 and 24576x512)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m     30\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[0;32m---> 31\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(epochs),losses)\n\u001b[1;32m     34\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "Cell \u001b[0;32mIn[6], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, criterion, optimizer, epochs)\u001b[0m\n\u001b[1;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Backward pass and optimize\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[4], line 48\u001b[0m, in \u001b[0;36mKeystrokeCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     44\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flatten dynamically\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Fully connected layers\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     49\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x30720 and 24576x512)"
     ]
    }
   ],
   "source": [
    "# Function to train the model\n",
    "def train(model, train_loader, criterion, optimizer, epochs=5):\n",
    "    model.train()  # Set the model to training mode\n",
    "    \n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            try: \n",
    "                outputs = model(inputs)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "                running_loss += loss.item()\n",
    "            #if i % 200 == 199:  # Print every 200 batches\n",
    "                print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 200:.3f}\")    \n",
    "\n",
    "                losses.append(loss.item())\n",
    "            except: \n",
    "                print(\"Input tensors may not be of the right shape\")\n",
    "\n",
    "    return losses\n",
    "\n",
    "# Train the model\n",
    "epochs = 50\n",
    "losses = train(model, train_loader, criterion, optimizer, epochs)\n",
    "\n",
    "plt.plot(range(epochs),losses)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 129, 101])\n",
      "size of x torch.Size([1, 1, 129, 101])\n",
      "Predicted letter: j\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Define character mapping (should match what you used in training)\n",
    "letters = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "idx2char = {i: c for i, c in enumerate(letters)}\n",
    "\n",
    "def predict(model, spectrogram_tensor):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    with torch.no_grad():  # No need to compute gradients\n",
    "        spectrogram_tensor = spectrogram_tensor.unsqueeze(0)  # Add batch dimension (1, 1, 129, 101)\n",
    "        output = model(spectrogram_tensor)  # Forward pass\n",
    "        probabilities = F.softmax(output, dim=1)  # Convert logits to probabilities\n",
    "        predicted_idx = torch.argmax(probabilities, dim=1).item()  # Get class index\n",
    "        predicted_letter = idx2char[predicted_idx]  # Convert index to letter\n",
    "        \n",
    "    return predicted_letter\n",
    "\n",
    "\n",
    "def crop_spectrogram(tensor, target_width=101):\n",
    "    return tensor[:, :, :target_width]  # Keep only the first 101 columns\n",
    "\n",
    "\n",
    "test_tensor = crop_spectrogram(spectrogram_tensors[5], target_width=101)\n",
    "print(test_tensor.shape)  # torch.Size([1, 1, 129, 101])\n",
    "\n",
    "predicted_letter = predict(model, test_tensor)\n",
    "print(f\"Predicted letter: {predicted_letter}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
